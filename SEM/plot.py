import re
import matplotlib.pyplot as plt

def plot_sem_acc_by_layer(acc_json: dict, out_path: str):
    """
    Plot SEM probe accuracy vs. layer from a dict like:
      {"ACC(normL2)@layer_1": 0.12, "ACC(normL2)@layer_2": 0.15, ...}
    and save the figure to `out_path` (e.g., "sem_layers.png").

    Args:
        acc_json: dict mapping "ACC@layer_<n>" -> float accuracy
        out_path: filepath to save the plot (png/pdf/svg, etc.)
    """


    # Extract (layer, acc) pairs and sort by layer number
    pairs = []
    pat = re.compile(r"ACC_both@layer_(\d+)$")
    for k, v in acc_json.items():
        m = pat.match(k)
        if m:
            pairs.append((int(m.group(1)), float(v)))
    if not pairs:
        raise ValueError("No keys matching 'ACC@layer_<n>' found in acc_json.")

    pairs.sort(key=lambda x: x[0])
    layers = [p[0] for p in pairs]
    accs   = [p[1] for p in pairs]

    # Find best layer for annotation
    best_idx = max(range(len(accs)), key=lambda i: accs[i])
    best_layer, best_acc = layers[best_idx], accs[best_idx]

    # Plot
    plt.figure(figsize=(9, 5))
    plt.plot(layers, accs, marker="o")
    plt.title("SEM Probe Accuracy by Layer")
    plt.xlabel("Layer")
    plt.ylabel("Accuracy")
    plt.grid(True, linestyle="--", linewidth=0.6)

    # Annotate best layer
    plt.scatter([best_layer], [best_acc])
    plt.annotate(
        f"best L{best_layer}: {best_acc:.3f}",
        xy=(best_layer, best_acc),
        xytext=(best_layer, best_acc + (max(accs) - min(accs)) * 0.05 if len(accs) > 1 else best_acc + 0.02),
        arrowprops=dict(arrowstyle="->", lw=0.8),
        ha="center",
    )

    plt.tight_layout()
    plt.savefig(out_path, dpi=200, bbox_inches="tight")
    plt.close()

metrics={
  "ACC_anchor@layer_1": 0.9512779552715654,
  "ACC_para@layer_1": 0.9946086261980831,
  "ACC_both@layer_1": 0.9498801916932907,
  "mean_d_ap@layer_1": 0.057700485479050934,
  "mean_d_an@layer_1": 0.12196832221632187,
  "mean_d_pn@layer_1": 0.13335415087759303,
  "ACC_anchor@layer_2": 0.9476837060702875,
  "ACC_para@layer_2": 0.9942092651757188,
  "ACC_both@layer_2": 0.9464856230031949,
  "mean_d_ap@layer_2": 0.05682613141239642,
  "mean_d_an@layer_2": 0.12053648596659255,
  "mean_d_pn@layer_2": 0.1318577413741773,
  "ACC_anchor@layer_3": 0.9103434504792333,
  "ACC_para@layer_3": 0.9748402555910544,
  "ACC_both@layer_3": 0.9051517571884984,
  "mean_d_ap@layer_3": 0.02998902573110387,
  "mean_d_an@layer_3": 0.06256806487425828,
  "mean_d_pn@layer_3": 0.07005569518517,
  "ACC_anchor@layer_4": 0.915535143769968,
  "ACC_para@layer_4": 0.9790335463258786,
  "ACC_both@layer_4": 0.911741214057508,
  "mean_d_ap@layer_4": 0.031155816115700778,
  "mean_d_an@layer_4": 0.06377375957826836,
  "mean_d_pn@layer_4": 0.07166224826401034,
  "ACC_anchor@layer_5": 0.9079472843450479,
  "ACC_para@layer_5": 0.9802316293929713,
  "ACC_both@layer_5": 0.9047523961661342,
  "mean_d_ap@layer_5": 0.025306753796367598,
  "mean_d_an@layer_5": 0.049227088642196534,
  "mean_d_pn@layer_5": 0.055760029858103195,
  "ACC_anchor@layer_6": 0.9035543130990416,
  "ACC_para@layer_6": 0.9836261980830671,
  "ACC_both@layer_6": 0.9017571884984026,
  "mean_d_ap@layer_6": 0.02350148519935509,
  "mean_d_an@layer_6": 0.042646867172500956,
  "mean_d_pn@layer_6": 0.0489283149329999,
  "ACC_anchor@layer_7": 0.8682108626198083,
  "ACC_para@layer_7": 0.9860223642172524,
  "ACC_both@layer_7": 0.8664137380191693,
  "mean_d_ap@layer_7": 0.01877436538438161,
  "mean_d_an@layer_7": 0.028806515948507732,
  "mean_d_pn@layer_7": 0.03440530307162493,
  "ACC_anchor@layer_8": 0.8500399361022364,
  "ACC_para@layer_8": 0.9860223642172524,
  "ACC_both@layer_8": 0.8472444089456869,
  "mean_d_ap@layer_8": 0.017359504339317926,
  "mean_d_an@layer_8": 0.025945253509540148,
  "mean_d_pn@layer_8": 0.031084488071620273,
  "ACC_anchor@layer_9": 0.8085063897763578,
  "ACC_para@layer_9": 0.987020766773163,
  "ACC_both@layer_9": 0.8049121405750799,
  "mean_d_ap@layer_9": 0.013329265540995346,
  "mean_d_an@layer_9": 0.01851793141148913,
  "mean_d_pn@layer_9": 0.022600098510091298,
  "ACC_anchor@layer_10": 0.7749600638977636,
  "ACC_para@layer_10": 0.985223642172524,
  "ACC_both@layer_10": 0.7693690095846646,
  "mean_d_ap@layer_10": 0.011831414186583159,
  "mean_d_an@layer_10": 0.015632953372792885,
  "mean_d_pn@layer_10": 0.019388042289180497,
  "ACC_anchor@layer_11": 0.7519968051118211,
  "ACC_para@layer_11": 0.9862220447284346,
  "ACC_both@layer_11": 0.7456070287539937,
  "mean_d_ap@layer_11": 0.01108296760045492,
  "mean_d_an@layer_11": 0.01446354668289899,
  "mean_d_pn@layer_11": 0.017944529209250267,
  "ACC_anchor@layer_12": 0.7386182108626198,
  "ACC_para@layer_12": 0.981629392971246,
  "ACC_both@layer_12": 0.7312300319488818,
  "mean_d_ap@layer_12": 0.010064641363359392,
  "mean_d_an@layer_12": 0.012847767869076028,
  "mean_d_pn@layer_12": 0.016085844861861234,
  "ACC_anchor@layer_13": 0.7282348242811502,
  "ACC_para@layer_13": 0.9810303514376997,
  "ACC_both@layer_13": 0.7204472843450479,
  "mean_d_ap@layer_13": 0.008779907411636827,
  "mean_d_an@layer_13": 0.011094220259342901,
  "mean_d_pn@layer_13": 0.013929644917932372,
  "ACC_anchor@layer_14": 0.7302316293929713,
  "ACC_para@layer_14": 0.9822284345047924,
  "ACC_both@layer_14": 0.722444089456869,
  "mean_d_ap@layer_14": 0.008232581586883472,
  "mean_d_an@layer_14": 0.01058032622221655,
  "mean_d_pn@layer_14": 0.0131671318379692,
  "ACC_anchor@layer_15": 0.7300319488817891,
  "ACC_para@layer_15": 0.9804313099041534,
  "ACC_both@layer_15": 0.7220447284345048,
  "mean_d_ap@layer_15": 0.0075905629725287705,
  "mean_d_an@layer_15": 0.009763545919054994,
  "mean_d_pn@layer_15": 0.01211289457155588,
  "ACC_anchor@layer_16": 0.7326277955271565,
  "ACC_para@layer_16": 0.9804313099041534,
  "ACC_both@layer_16": 0.7248402555910544,
  "mean_d_ap@layer_16": 0.007104094367855178,
  "mean_d_an@layer_16": 0.00918450152067045,
  "mean_d_pn@layer_16": 0.011345097940926925,
  "ACC_anchor@layer_17": 0.7380191693290735,
  "ACC_para@layer_17": 0.9756389776357828,
  "ACC_both@layer_17": 0.7288338658146964,
  "mean_d_ap@layer_17": 0.006973675364396348,
  "mean_d_an@layer_17": 0.00912248603136728,
  "mean_d_pn@layer_17": 0.01122405568655497,
  "ACC_anchor@layer_18": 0.7549920127795527,
  "ACC_para@layer_18": 0.979832268370607,
  "ACC_both@layer_18": 0.7472044728434505,
  "mean_d_ap@layer_18": 0.007265677160848253,
  "mean_d_an@layer_18": 0.009915094520634831,
  "mean_d_pn@layer_18": 0.011993716125742505,
  "ACC_anchor@layer_19": 0.748202875399361,
  "ACC_para@layer_19": 0.978035143769968,
  "ACC_both@layer_19": 0.7398162939297125,
  "mean_d_ap@layer_19": 0.00719674776930112,
  "mean_d_an@layer_19": 0.009834171960148188,
  "mean_d_pn@layer_19": 0.01187060600795304,
  "ACC_anchor@layer_20": 0.75,
  "ACC_para@layer_20": 0.9766373801916933,
  "ACC_both@layer_20": 0.7418130990415336,
  "mean_d_ap@layer_20": 0.007158249702911598,
  "mean_d_an@layer_20": 0.00979835367330109,
  "mean_d_pn@layer_20": 0.011794661255047535,
  "ACC_anchor@layer_21": 0.7226437699680511,
  "ACC_para@layer_21": 0.9718450479233227,
  "ACC_both@layer_21": 0.7110623003194888,
  "mean_d_ap@layer_21": 0.00735254547805689,
  "mean_d_an@layer_21": 0.00960079679926173,
  "mean_d_pn@layer_21": 0.011694437202316122,
  "ACC_anchor@layer_22": 0.7026757188498403,
  "ACC_para@layer_22": 0.9644568690095847,
  "ACC_both@layer_22": 0.6890974440894568,
  "mean_d_ap@layer_22": 0.00786065998168799,
  "mean_d_an@layer_22": 0.009867255943425642,
  "mean_d_pn@layer_22": 0.01218311365443868,
  "ACC_anchor@layer_23": 0.6785143769968051,
  "ACC_para@layer_23": 0.9592651757188498,
  "ACC_both@layer_23": 0.6633386581469649,
  "mean_d_ap@layer_23": 0.008837086519006247,
  "mean_d_an@layer_23": 0.01066714025343569,
  "mean_d_pn@layer_23": 0.01335916581887978,
  "ACC_anchor@layer_24": 0.6763178913738019,
  "ACC_para@layer_24": 0.9572683706070287,
  "ACC_both@layer_24": 0.6605431309904153,
  "mean_d_ap@layer_24": 0.009639282033930476,
  "mean_d_an@layer_24": 0.011598968238662036,
  "mean_d_pn@layer_24": 0.014486033029068774,
  "ACC_anchor@layer_25": 0.6425718849840255,
  "ACC_para@layer_25": 0.9516773162939297,
  "ACC_both@layer_25": 0.6246006389776357,
  "mean_d_ap@layer_25": 0.010211147423000477,
  "mean_d_an@layer_25": 0.011717433148560623,
  "mean_d_pn@layer_25": 0.014848505390790133,
  "ACC_anchor@layer_26": 0.6407747603833865,
  "ACC_para@layer_26": 0.9524760383386581,
  "ACC_both@layer_26": 0.623202875399361,
  "mean_d_ap@layer_26": 0.011946735293649065,
  "mean_d_an@layer_26": 0.013665150083339633,
  "mean_d_pn@layer_26": 0.01738935488517197,
  "ACC_anchor@layer_27": 0.6529552715654952,
  "ACC_para@layer_27": 0.9582667731629393,
  "ACC_both@layer_27": 0.6373801916932907,
  "mean_d_ap@layer_27": 0.01444800263240981,
  "mean_d_an@layer_27": 0.01694768670494088,
  "mean_d_pn@layer_27": 0.021305115905385048,
  "ACC_anchor@layer_28": 0.7024760383386581,
  "ACC_para@layer_28": 0.9710463258785943,
  "ACC_both@layer_28": 0.689297124600639,
  "mean_d_ap@layer_28": 0.017150036008736956,
  "mean_d_an@layer_28": 0.021690836509529014,
  "mean_d_pn@layer_28": 0.026457673444534643,
  "ACC_anchor@layer_29": 0.7342252396166135,
  "ACC_para@layer_29": 0.9756389776357828,
  "ACC_both@layer_29": 0.7218450479233227,
  "mean_d_ap@layer_29": 0.019727664291501617,
  "mean_d_an@layer_29": 0.02621957472266671,
  "mean_d_pn@layer_29": 0.03142234409888522,
  "ACC_anchor@layer_30": 0.7519968051118211,
  "ACC_para@layer_30": 0.978035143769968,
  "ACC_both@layer_30": 0.7400159744408946,
  "mean_d_ap@layer_30": 0.021504185620707255,
  "mean_d_an@layer_30": 0.029405388778771836,
  "mean_d_pn@layer_30": 0.034861788308372894,
  "ACC_anchor@layer_31": 0.7697683706070287,
  "ACC_para@layer_31": 0.9800319488817891,
  "ACC_both@layer_31": 0.7583865814696485,
  "mean_d_ap@layer_31": 0.022546033669536867,
  "mean_d_an@layer_31": 0.031823034555957724,
  "mean_d_pn@layer_31": 0.037318056526656346,
  "ACC_anchor@layer_32": 0.8196884984025559,
  "ACC_para@layer_32": 0.9892172523961661,
  "ACC_both@layer_32": 0.8134984025559105,
  "mean_d_ap@layer_32": 0.024834653695884605,
  "mean_d_an@layer_32": 0.03795580530223755,
  "mean_d_pn@layer_32": 0.04346341542161692,
  "ACC_anchor@layer_33": 0.8428514376996805,
  "ACC_para@layer_33": 0.9902156549520766,
  "ACC_both@layer_33": 0.8376597444089456,
  "mean_d_ap@layer_33": 0.026564416056052566,
  "mean_d_an@layer_33": 0.042440829590296214,
  "mean_d_pn@layer_33": 0.04796380886492638,
  "ACC_anchor@layer_34": 0.8520367412140575,
  "ACC_para@layer_34": 0.9906150159744409,
  "ACC_both@layer_34": 0.8470447284345048,
  "mean_d_ap@layer_34": 0.028740980052433838,
  "mean_d_an@layer_34": 0.04685831291321368,
  "mean_d_pn@layer_34": 0.05258606025538506,
  "ACC_anchor@layer_35": 0.8644169329073482,
  "ACC_para@layer_35": 0.9902156549520766,
  "ACC_both@layer_35": 0.8592252396166135,
  "mean_d_ap@layer_35": 0.029598477144782153,
  "mean_d_an@layer_35": 0.049092772455451586,
  "mean_d_pn@layer_35": 0.054806593519906265,
  "ACC_anchor@layer_36": 0.8712060702875399,
  "ACC_para@layer_36": 0.9906150159744409,
  "ACC_both@layer_36": 0.8662140575079872,
  "mean_d_ap@layer_36": 0.03106706463300382,
  "mean_d_an@layer_36": 0.0519568926919573,
  "mean_d_pn@layer_36": 0.05775324323068792,
  "ACC_anchor@layer_37": 0.8817891373801917,
  "ACC_para@layer_37": 0.9898162939297125,
  "ACC_both@layer_37": 0.876797124600639,
  "mean_d_ap@layer_37": 0.0336858550973308,
  "mean_d_an@layer_37": 0.058470241392191986,
  "mean_d_pn@layer_37": 0.06436923428322561,
  "ACC_anchor@layer_38": 0.8847843450479234,
  "ACC_para@layer_38": 0.9902156549520766,
  "ACC_both@layer_38": 0.8797923322683706,
  "mean_d_ap@layer_38": 0.03401981314983421,
  "mean_d_an@layer_38": 0.05930679760421046,
  "mean_d_pn@layer_38": 0.06510634463244734,
  "ACC_anchor@layer_39": 0.8913738019169329,
  "ACC_para@layer_39": 0.990814696485623,
  "ACC_both@layer_39": 0.8871805111821086,
  "mean_d_ap@layer_39": 0.03582436572938872,
  "mean_d_an@layer_39": 0.06341178680713565,
  "mean_d_pn@layer_39": 0.06926088718274911,
  "ACC_anchor@layer_40": 0.8883785942492013,
  "ACC_para@layer_40": 0.9898162939297125,
  "ACC_both@layer_40": 0.8835862619808307,
  "mean_d_ap@layer_40": 0.03693398299475257,
  "mean_d_an@layer_40": 0.06462556099929749,
  "mean_d_pn@layer_40": 0.07061574417657365,
  "ACC_anchor@layer_41": 0.8851837060702875,
  "ACC_para@layer_41": 0.9892172523961661,
  "ACC_both@layer_41": 0.8797923322683706,
  "mean_d_ap@layer_41": 0.03612657948828543,
  "mean_d_an@layer_41": 0.062393218588333924,
  "mean_d_pn@layer_41": 0.06823546296586624,
  "ACC_anchor@layer_42": 0.8861821086261981,
  "ACC_para@layer_42": 0.9894169329073482,
  "ACC_both@layer_42": 0.8811900958466453,
  "mean_d_ap@layer_42": 0.03784893932172094,
  "mean_d_an@layer_42": 0.06538861230634653,
  "mean_d_pn@layer_42": 0.07142456873251607,
  "ACC_anchor@layer_43": 0.8829872204472844,
  "ACC_para@layer_43": 0.9896166134185304,
  "ACC_both@layer_43": 0.8777955271565495,
  "mean_d_ap@layer_43": 0.03960974315127816,
  "mean_d_an@layer_43": 0.06910036768490514,
  "mean_d_pn@layer_43": 0.07529557791476052,
  "ACC_anchor@layer_44": 0.8815894568690096,
  "ACC_para@layer_44": 0.9890175718849841,
  "ACC_both@layer_44": 0.8763977635782748,
  "mean_d_ap@layer_44": 0.040627294871658566,
  "mean_d_an@layer_44": 0.07110103917198059,
  "mean_d_pn@layer_44": 0.07739600308310872,
  "ACC_anchor@layer_45": 0.8785942492012779,
  "ACC_para@layer_45": 0.9876198083067093,
  "ACC_both@layer_45": 0.873202875399361,
  "mean_d_ap@layer_45": 0.04220529392171211,
  "mean_d_an@layer_45": 0.07402784735583269,
  "mean_d_pn@layer_45": 0.08055001468704151,
  "ACC_anchor@layer_46": 0.8785942492012779,
  "ACC_para@layer_46": 0.9858226837060703,
  "ACC_both@layer_46": 0.8718051118210862,
  "mean_d_ap@layer_46": 0.044682198510573694,
  "mean_d_an@layer_46": 0.07948403772169028,
  "mean_d_pn@layer_46": 0.08610409481552081,
  "ACC_anchor@layer_47": 0.884185303514377,
  "ACC_para@layer_47": 0.9856230031948882,
  "ACC_both@layer_47": 0.8769968051118211,
  "mean_d_ap@layer_47": 0.0446580178892841,
  "mean_d_an@layer_47": 0.08045232226959052,
  "mean_d_pn@layer_47": 0.08686261638380087
}

plot_sem_acc_by_layer(metrics, "./sem_lens_ckpt/Gemma-12b-pt.png")